{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"MGyQVFJ5Xfmf"},"outputs":[],"source":["#ID3\n","\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.preprocessing import LabelEncoder "]},{"cell_type":"code","source":["data = pd.read_csv('id3.csv')\n","print(\"Sample Dataset - \\n\",data,\"\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qRwtWLJxXpd7","executionInfo":{"status":"ok","timestamp":1679825022719,"user_tz":-330,"elapsed":5,"user":{"displayName":"Shashank Venkat","userId":"02161020895175553394"}},"outputId":"3ffe07ea-66cd-4daf-d987-ff7dedd01d52"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sample Dataset - \n","       a1    a2      a3 classification\n","0   True   Hot    High             No\n","1   True   Hot    High             No\n","2  False   Hot    High            Yes\n","3  False  Cool  Normal            Yes\n","4  False  Cool  Normal            Yes\n","5   True  Cool    High             No\n","6   True   Hot    High             No\n","7   True   Hot  Normal            Yes\n","8  False  Cool  Normal            Yes\n","9  False  Cool    High            Yes \n","\n"]}]},{"cell_type":"code","source":["le_a1 = LabelEncoder()\n","data['a1_n'] = le_a1.fit_transform(data['a1'])\n","\n","le_a2 = LabelEncoder()\n","data['a2_n'] = le_a1.fit_transform(data['a2'])\n","\n","le_a3 = LabelEncoder()\n","data['a3_n'] = le_a1.fit_transform(data['a3'])\n","\n","print(\"Given Data after Encoding - \\n\",data,\"\\n\") "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ALUpb1LxXs0J","executionInfo":{"status":"ok","timestamp":1679825024632,"user_tz":-330,"elapsed":4,"user":{"displayName":"Shashank Venkat","userId":"02161020895175553394"}},"outputId":"42045ee6-f024-49bb-d8a4-ca9caea7d24f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Given Data after Encoding - \n","       a1    a2      a3 classification  a1_n  a2_n  a3_n\n","0   True   Hot    High             No     1     1     0\n","1   True   Hot    High             No     1     1     0\n","2  False   Hot    High            Yes     0     1     0\n","3  False  Cool  Normal            Yes     0     0     1\n","4  False  Cool  Normal            Yes     0     0     1\n","5   True  Cool    High             No     1     0     0\n","6   True   Hot    High             No     1     1     0\n","7   True   Hot  Normal            Yes     1     1     1\n","8  False  Cool  Normal            Yes     0     0     1\n","9  False  Cool    High            Yes     0     0     0 \n","\n"]}]},{"cell_type":"code","source":["X = data[['a1_n','a2_n','a3_n']]\n","print(\"X - Values\\n\",X,\"\\n\")\n","\n","y = data['classification']\n","print(\"Y - Values\\n\",y,\"\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0fjSG5VkXwNH","executionInfo":{"status":"ok","timestamp":1679825030771,"user_tz":-330,"elapsed":443,"user":{"displayName":"Shashank Venkat","userId":"02161020895175553394"}},"outputId":"8bcbe988-b09f-4f1d-f30a-43f06c62d5b6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["X - Values\n","    a1_n  a2_n  a3_n\n","0     1     1     0\n","1     1     1     0\n","2     0     1     0\n","3     0     0     1\n","4     0     0     1\n","5     1     0     0\n","6     1     1     0\n","7     1     1     1\n","8     0     0     1\n","9     0     0     0 \n","\n","Y - Values\n"," 0     No\n","1     No\n","2    Yes\n","3    Yes\n","4    Yes\n","5     No\n","6     No\n","7    Yes\n","8    Yes\n","9    Yes\n","Name: classification, dtype: object \n","\n"]}]},{"cell_type":"code","source":["X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)\n","\n","model = DecisionTreeClassifier(criterion='entropy')\n","model.fit(X_train,y_train)\n","\n","print(\"Values predicted from test dataset - \",model.predict(X_test))\n","print(\"Original Values of test dataset - \",y_test.values)\n","print(\"Accuracy of Model\",model.score(X_test,y_test)) "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VE5DUxb6Xycf","executionInfo":{"status":"ok","timestamp":1679825032892,"user_tz":-330,"elapsed":4,"user":{"displayName":"Shashank Venkat","userId":"02161020895175553394"}},"outputId":"579b91a8-988a-449c-bbec-fea4081cbd51"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Values predicted from test dataset -  ['Yes' 'No' 'Yes']\n","Original Values of test dataset -  ['Yes' 'No' 'Yes']\n","Accuracy of Model 1.0\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"PZV49tddX1Ia"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"mMt4SavixPjf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import math\n","\n","def entropy(data, target_attribute):\n","    # Calculate the entropy of a dataset\n","    target_labels = data[target_attribute].unique()\n","    entropy = 0\n","    for label in target_labels:\n","        count = len(data[data[target_attribute] == label])\n","        p = count / len(data)\n","        entropy -= p * math.log2(p)\n","    return entropy\n","\n","def information_gain(data, attribute, target_attribute):\n","    # Calculate the information gain of an attribute in a dataset\n","    attribute_values = data[attribute].unique()\n","    gain = entropy(data, target_attribute)\n","    for value in attribute_values:\n","        subset = data[data[attribute] == value]\n","        p = len(subset) / len(data)\n","        gain -= p * entropy(subset, target_attribute)\n","    return gain\n","\n","def id3(data, attributes, target_attribute):\n","    # Build a decision tree using the ID3 algorithm\n","    unique_labels = data[target_attribute].unique()\n","    if len(unique_labels) == 1:\n","        # If all examples have the same label, return a leaf node with that label\n","        return unique_labels[0]\n","    if len(attributes) == 0:\n","        # If there are no more attributes to split on, return a leaf node with the majority label\n","        label_counts = data[target_attribute].value_counts()\n","        return label_counts.index[0]\n","    best_attribute = max(attributes, key=lambda attribute: information_gain(data, attribute, target_attribute))\n","    tree = {best_attribute: {}}\n","    remaining_attributes = [attribute for attribute in attributes if attribute != best_attribute]\n","    for value in data[best_attribute].unique():\n","        subset = data[data[best_attribute] == value]\n","        if len(subset) == 0:\n","            # If there are no examples with this value, return a leaf node with the majority label\n","            label_counts = data[target_attribute].value_counts()\n","            tree[best_attribute][value] = label_counts.index[0]\n","        else:\n","            # Recursively build the subtree using the remaining attributes\n","            tree[best_attribute][value] = id3(subset, remaining_attributes, target_attribute)\n","    return tree\n","\n","def predict(row, tree):\n","    # Traverse the decision tree until a leaf node is reached\n","    while type(tree) == dict:\n","        attribute = list(tree.keys())[0]\n","        value = row[attribute]\n","        if value not in tree[attribute]:\n","            # If the value is not in the decision tree, return the majority class\n","            label_counts = {}\n","            for label in tree[attribute].values():\n","                if label not in label_counts:\n","                    label_counts[label] = 0\n","                label_counts[label] += 1\n","            return max(label_counts, key=label_counts.get)\n","        tree = tree[attribute][value]\n","    return tree\n","\n","# Load the tennis dataset\n","data = pd.read_csv('tennis.csv')\n","\n","# Define the target attribute\n","target_attribute = 'play'\n","\n","# Define the attributes\n","attributes = list(data.columns)\n","attributes.remove(target_attribute)\n","\n","# Split the data into training and testing sets\n","split_index = int(0.8 * len(data))\n","train_data = data.iloc[:split_index]\n","test_data = data.iloc[split_index:]\n","\n","# Train the decision tree\n","tree = id3(train_data, attributes, target_attribute)\n","\n","# Test the decision tree\n","correct_predictions = 0\n","for index, row in test_data.iterrows():\n","    if predict(row, tree) == row[target_attribute]:\n","        correct_predictions += 1\n","\n","accuracy = correct_predictions\n","accuracy = correct_predictions / len(test_data)\n","print(f\"Accuracy: {accuracy}\")"],"metadata":{"id":"_nr5p70NxPoY","executionInfo":{"status":"ok","timestamp":1680887433974,"user_tz":-330,"elapsed":2193,"user":{"displayName":"Shashank Venkat","userId":"02161020895175553394"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"bcfdbbb7-c858-4515-db70-24932d5d466b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.6666666666666666\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"rew3Y-Ghxbbj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["CART ALGO without lib"],"metadata":{"id":"frAk6NQktKJB"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","# Define the Node class to represent a decision tree node\n","class Node:\n","    def __init__(self, feature=None, threshold=None, left=None, right=None, label=None):\n","        self.feature = feature  # index of feature to split on\n","        self.threshold = threshold  # threshold to split on\n","        self.left = left  # left subtree\n","        self.right = right  # right subtree\n","        self.label = label  # label of leaf node\n","\n","# Define the decision tree function\n","def decision_tree(X, y):\n","    n, m = X.shape\n","\n","    # Base case: all labels are the same\n","    if len(np.unique(y)) == 1:\n","        return Node(label=y[0])\n","\n","    # Base case: no more features to split on\n","    if m == 0:\n","        return Node(label=np.bincount(y).argmax())\n","\n","    # Find the best feature to split on\n","    best_feature, best_threshold, min_gini = None, None, 1.0\n","    for i in range(m):\n","        for threshold in np.unique(X[:, i]):\n","            left_indices = X[:, i] < threshold\n","            left_y = y[left_indices]\n","            right_y = y[~left_indices]\n","            if len(left_y) > 0 and len(right_y) > 0:\n","                gini = (len(left_y) / n) * gini_index(left_y) + (len(right_y) / n) * gini_index(right_y)\n","                if gini < min_gini:\n","                    best_feature, best_threshold, min_gini = i, threshold, gini\n","\n","    # Create the node and its subtrees\n","    left_indices = X[:, best_feature] < best_threshold\n","    left = decision_tree(X[left_indices], y[left_indices])\n","    right = decision_tree(X[~left_indices], y[~left_indices])\n","    return Node(feature=best_feature, threshold=best_threshold, left=left, right=right)\n","\n","# Define the Gini index function\n","def gini_index(y):\n","    _, counts = np.unique(y, return_counts=True)\n","    probs = counts / len(y)\n","    return 1 - np.sum(probs ** 2)\n","\n","# Test the decision tree on the iris dataset\n","from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split\n","\n","iris = load_iris()\n","X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=42)\n","\n","tree = decision_tree(X_train, y_train)\n","\n","# Define a function to predict the label of a single instance using the decision tree\n","def predict(instance, tree):\n","    if tree.label is not None:\n","        return tree.label\n","    elif instance[tree.feature] < tree.threshold:\n","        return predict(instance, tree.left)\n","    else:\n","        return predict(instance, tree.right)\n","\n","# Test the accuracy of the decision tree on the test set\n","y_pred = np.array([predict(instance, tree) for instance in X_test])\n","accuracy = np.mean(y_pred == y_test)\n","print(f\"Accuracy: {accuracy}\")\n"],"metadata":{"id":"6N95QJU8xdQi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681138161428,"user_tz":-330,"elapsed":2037,"user":{"displayName":"Shashank Venkat","userId":"02161020895175553394"}},"outputId":"a8bb516a-4087-48da-c9a3-fb212fee5303"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 1.0\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"8LG2ao15uJhd"},"execution_count":null,"outputs":[]}]}